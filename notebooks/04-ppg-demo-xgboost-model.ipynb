{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be813e62",
   "metadata": {},
   "source": [
    "### Model development based on demographic features, pyPPG features, and xgboost architecture\n",
    "\n",
    "*Date:* 2025-06-19 <br> \n",
    "*Author:* salil apte  <br> \n",
    "*Version:* 1.0  <br> \n",
    "*Filename:* `04-ppg-demo-xgboost-model.ipynb`\n",
    "\n",
    "This notebook contains the training and evaluation of a [xgboost](https://xgboost.readthedocs.io) model using the five demographic features and the [pyPPG](https://pyppg.readthedocs.io) features. The process is repeated 50 times with different training/validation splits, which are designed to not have any overlap of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bf1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ac696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df_demo = pd.read_parquet(r\"E:\\repos\\vital-sign-estimation\\data\\processed\\demographics.parquet\")\n",
    "df_ppg = pd.read_parquet(r\"E:\\repos\\vital-sign-estimation\\data\\processed\\features.parquet\")\n",
    "labels = pd.read_csv(r\"E:\\repos\\vital-sign-estimation\\data\\raw\\train_labels.csv\")\n",
    "df = pd.concat([df_demo, df_ppg], axis=1)\n",
    "df.drop(columns=[\"id\"], inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features, labels, and user ids\n",
    "X = df.to_numpy()\n",
    "y = labels.to_numpy()\n",
    "unique_ids = df_demo[\"id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801e426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training and model parameters\n",
    "n_bootstraps = 50\n",
    "test_size = 0.2\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.03,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"reg_alpha\": 3.0,\n",
    "    \"reg_lambda\": 2.0,\n",
    "    \"seed\": 1,\n",
    "    \"tree_method\": \"gpu_hist\",  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training run\n",
    "def training_run(i):\n",
    "    # Split the ids for training and testing    \n",
    "    train_ids, test_ids = train_test_split(unique_ids, test_size=test_size, random_state=i)\n",
    "\n",
    "    train_mask = df_demo[\"id\"].isin(train_ids)\n",
    "    test_mask = df_demo[\"id\"].isin(test_ids)\n",
    "\n",
    "    # Split the train and test dataset\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val, y_val = X[test_mask], y[test_mask]\n",
    "\n",
    "    # Create DMatrix objects\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "\n",
    "    # Train model with early stopping\n",
    "    evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "    model = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=400,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(dval)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "\n",
    "    return {\"seed\": i, \"mse\": mse, \"mape\": mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 50 training runs in parallel\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(training_run)(i) for i in tqdm(range(n_bootstraps))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate the results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.describe())\n",
    "\n",
    "# Visualize the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=results_df[[\"mse\", \"mape\"]])\n",
    "plt.title(\"XGBoost with PPG and demo features - 50 Bootstrap Runs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
